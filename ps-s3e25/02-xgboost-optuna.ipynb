{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60892,"databundleVersionId":6989718,"sourceType":"competition"},{"sourceId":6612067,"sourceType":"datasetVersion","datasetId":3815527}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"import gc\nimport time\nimport warnings\nimport subprocess\n\ngc.enable()\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\npd.set_option('display.max_columns', None)\n\nfrom sklearn.metrics import median_absolute_error\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nimport optuna\n\nSEED = 55","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-16T11:09:28.841573Z","iopub.execute_input":"2023-11-16T11:09:28.842195Z","iopub.status.idle":"2023-11-16T11:09:31.465303Z","shell.execute_reply.started":"2023-11-16T11:09:28.842166Z","shell.execute_reply":"2023-11-16T11:09:31.464330Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"assert xgb.__version__ == '2.0.1', 'XGBoost version differs from original notebook.' ","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:31.467068Z","iopub.execute_input":"2023-11-16T11:09:31.467582Z","iopub.status.idle":"2023-11-16T11:09:31.473000Z","shell.execute_reply.started":"2023-11-16T11:09:31.467549Z","shell.execute_reply":"2023-11-16T11:09:31.472194Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Check GPU availability\ntry:\n    subprocess.check_output('nvidia-smi')\n    DEVICE = 'cuda'\nexcept Exception:\n    DEVICE = 'cpu'\n\nprint(f'Available device: {DEVICE}')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:31.474257Z","iopub.execute_input":"2023-11-16T11:09:31.474967Z","iopub.status.idle":"2023-11-16T11:09:31.523400Z","shell.execute_reply.started":"2023-11-16T11:09:31.474933Z","shell.execute_reply":"2023-11-16T11:09:31.522322Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Available device: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/playground-series-s3e25'\ntrain = pd.read_csv(f'{DATA_DIR}/train.csv')\ntest = pd.read_csv(f'{DATA_DIR}/test.csv')\nsample_sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n\noriginal_train = pd.read_csv(f'/kaggle/input/prediction-of-mohs-hardness-with-machine-learning/jm79zfps6b-1/Mineral_Dataset_Supplementary_Info.csv')\noriginal_val = pd.read_csv(f'/kaggle/input/prediction-of-mohs-hardness-with-machine-learning/jm79zfps6b-1/Artificial_Crystals_Dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:31.528678Z","iopub.execute_input":"2023-11-16T11:09:31.528961Z","iopub.status.idle":"2023-11-16T11:09:31.645072Z","shell.execute_reply.started":"2023-11-16T11:09:31.528935Z","shell.execute_reply":"2023-11-16T11:09:31.644192Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# fixing coluumn names\noriginal_val.rename({'Hardness (Mohs)': 'Hardness'}, axis=1, inplace=True)\n\n# dropping irrelevant columns\ntrain.drop('id', axis=1, inplace=True)\ntest.drop('id', axis=1, inplace=True)\noriginal_train.drop('Unnamed: 0', axis=1, inplace=True)\noriginal_val.drop(['Unnamed: 0', 'Formula', 'Crystal structure'], axis=1, inplace=True)\n\n# fixing column order\ncolumn_order = list(train.columns)\noriginal_train = original_train[column_order]\noriginal_val = original_val[column_order]\n\n# combining original train and validation datasets\noriginal = pd.concat([original_train, original_val], axis=0, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:31.646424Z","iopub.execute_input":"2023-11-16T11:09:31.646780Z","iopub.status.idle":"2023-11-16T11:09:31.670275Z","shell.execute_reply.started":"2023-11-16T11:09:31.646747Z","shell.execute_reply":"2023-11-16T11:09:31.669194Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"TARGET = 'Hardness'\nfeatures = list(test.columns)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:31.671819Z","iopub.execute_input":"2023-11-16T11:09:31.672760Z","iopub.status.idle":"2023-11-16T11:09:31.678019Z","shell.execute_reply.started":"2023-11-16T11:09:31.672725Z","shell.execute_reply":"2023-11-16T11:09:31.676858Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Baseline","metadata":{}},{"cell_type":"code","source":"# competition metric\ndef comp_metric(y_true, y_pred):\n    return median_absolute_error(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:31.679571Z","iopub.execute_input":"2023-11-16T11:09:31.679982Z","iopub.status.idle":"2023-11-16T11:09:31.688013Z","shell.execute_reply.started":"2023-11-16T11:09:31.679948Z","shell.execute_reply":"2023-11-16T11:09:31.687114Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X, y = train[features], train[TARGET]\noof_preds = {}\n\ncv = KFold(n_splits=7, shuffle=True, random_state=SEED)\nfor fold, (train_ids, val_ids) in enumerate(cv.split(X, y)):\n    X_train, y_train = X.iloc[train_ids], y.iloc[train_ids]\n    X_val, y_val = X.iloc[val_ids], y.iloc[val_ids]\n    \n    model = xgb.XGBRegressor(\n        n_estimators=1000,\n        learning_rate=0.1,\n        base_score=0,\n        objective='reg:absoluteerror',\n        eval_metric=comp_metric,\n        early_stopping_rounds=100,\n        booster='gbtree',\n        tree_method='hist',\n        device=DEVICE,\n        verbosity=0,\n        n_jobs=4,\n        random_state=SEED)\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        verbose=False)\n        \n    val_preds = model.predict(X_val)\n    oof_preds.update(dict(zip(val_ids, val_preds)))\n    \n    score = comp_metric(y_val, val_preds)\n    print(f'Fold #{fold}: {score:.4f}', end = ' | ')        \n    _ = gc.collect()\n    \noof_preds = pd.Series(oof_preds).sort_index()\nprint(f'OOF score: {comp_metric(y, oof_preds):.4f}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:31.691663Z","iopub.execute_input":"2023-11-16T11:09:31.692015Z","iopub.status.idle":"2023-11-16T11:09:40.913440Z","shell.execute_reply.started":"2023-11-16T11:09:31.691989Z","shell.execute_reply":"2023-11-16T11:09:40.912476Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Fold #0: 0.5530 | Fold #1: 0.5240 | Fold #2: 0.5246 | Fold #3: 0.5139 | Fold #4: 0.4672 | Fold #5: 0.5920 | Fold #6: 0.5972 | OOF score: 0.5373\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"def objective(trial, feature_set, model, num_folds, seed, extended):\n    oof_preds = {}\n    X, y = train[feature_set], train[TARGET]\n    \n    param_grid = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, step=0.01),\n        'max_depth': trial.suggest_int('max_depth', 3, 12),\n        'min_child_weight': trial.suggest_int('min_child_weight', 2, 15),\n        'gamma': trial.suggest_float('gamma', 0, 20, step=0.1), #complexity-control\n        'alpha': trial.suggest_float('alpha', 0, 5, step=0.05), #L1-reg\n        'lambda': trial.suggest_float('lambda', 5e-3, 5e3, log=True), #L2-reg\n    }\n    \n    cv = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n        \n        if extended: # original data added only to training folds\n            X_train = pd.concat([X_train, original[feature_set]], axis=0, ignore_index=True)\n            y_train = pd.concat([y_train, original[TARGET]], axis=0, ignore_index=True)\n        \n        model.set_params(**param_grid)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=0)\n        \n        val_preds = model.predict(X_val)\n        oof_preds.update(dict(zip(val_idx, val_preds)))\n        \n    oof_preds = pd.Series(oof_preds).sort_index()\n    return comp_metric(y, oof_preds)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.073691Z","iopub.execute_input":"2023-11-16T11:09:51.074479Z","iopub.status.idle":"2023-11-16T11:09:51.084845Z","shell.execute_reply.started":"2023-11-16T11:09:51.074445Z","shell.execute_reply":"2023-11-16T11:09:51.083796Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def tune_params(feature_set, model, num_folds, seed, extended, n_trials, direction):\n    study = optuna.create_study(\n        sampler=optuna.samplers.TPESampler(\n            consider_endpoints=True,\n            multivariate=True,\n            group=True,\n            seed=seed),\n        pruner=optuna.pruners.HyperbandPruner(),\n        direction=direction\n    )\n    study.optimize(\n        func=lambda trial: objective(\n            trial, feature_set, model, num_folds, seed, extended\n        ),\n        n_trials=n_trials,\n        gc_after_trial=True\n    )\n    return study","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.092436Z","iopub.execute_input":"2023-11-16T11:09:51.092737Z","iopub.status.idle":"2023-11-16T11:09:51.100771Z","shell.execute_reply.started":"2023-11-16T11:09:51.092712Z","shell.execute_reply":"2023-11-16T11:09:51.099917Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation","metadata":{}},{"cell_type":"code","source":"def cross_validate_predict(feature_set, model, num_folds, seed, extended):\n    oof_preds = {}\n    test_preds = {}\n    scores = []\n\n    X, y = train[feature_set], train[TARGET]\n    X_test = test[feature_set]\n       \n    cv = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n        \n        if extended: # original data added only to training folds\n            X_train = pd.concat([X_train, original[feature_set]], axis=0, ignore_index=True)\n            y_train = pd.concat([y_train, original[TARGET]], axis=0, ignore_index=True)\n        \n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=0)\n\n        val_preds = model.predict(X_val)\n        test_preds[f'fold{fold}'] = model.predict(X_test)\n        oof_preds.update(dict(zip(val_idx, val_preds)))\n\n        score = comp_metric(y_val, val_preds)\n        scores.append(score)\n        print(f'Fold #{fold}: {score:.5f} ({model.best_iteration} rounds)')\n        _ = gc.collect()\n    \n    test_preds = pd.DataFrame.from_dict(test_preds)\n    test_preds['mean'] = test_preds.mean(axis=1)\n    \n    oof_preds = pd.Series(oof_preds).sort_index()\n    print(f'\\nOOF score: {comp_metric(y, oof_preds):.5f}\\n')\n\n    return oof_preds, test_preds","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.106374Z","iopub.execute_input":"2023-11-16T11:09:51.106680Z","iopub.status.idle":"2023-11-16T11:09:51.116926Z","shell.execute_reply.started":"2023-11-16T11:09:51.106656Z","shell.execute_reply":"2023-11-16T11:09:51.115940Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def run_experiment(feature_set, num_folds=5, seed=SEED, n_trials=100, extended=False):\n    \n    base_params = {\n        'booster': 'gbtree',\n        'tree_method': 'hist',\n        'base_score': 0,\n#         'objective': 'reg:absoluteerror',\n        'objective': 'reg:quantileerror',\n        'quantile_alpha': 0.5,\n        'n_estimators': 5000,\n        'eval_metric': comp_metric,\n        'early_stopping_rounds': 50,\n        'device': DEVICE,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'seed': seed\n    }\n    \n    model = xgb.XGBRegressor(**base_params)\n    \n    print(f'----------Hyperparameter tuning----------')\n    start = time.time()\n    study = tune_params(\n        feature_set=feature_set,\n        model=model,\n        num_folds=num_folds,\n        seed=seed,\n        extended=extended,\n        n_trials=n_trials, \n        direction='minimize' #metric: MedAE -> lower is better\n    )\n    end = time.time()\n    print(f'Best trial: {study.best_trial.number} -> Best value: {study.best_value:.5f}')\n    print(f'Best hyperparameters:')\n    for k, v in study.best_params.items():\n        print(f'{k:15} - {v}')\n    print(f'\\n[Time taken: {end - start:.2f}s]\\n')\n    \n    print(f'-----Cross-validation and prediction-----')\n    start = time.time()\n    model.set_params(**study.best_params)\n    oof_preds, test_preds = cross_validate_predict(\n        feature_set, model, num_folds, seed, extended\n    )\n    end = time.time()\n    print(f'[Time taken: {end - start:.2f}s]\\n')\n    \n    return oof_preds, test_preds","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.138446Z","iopub.execute_input":"2023-11-16T11:09:51.139123Z","iopub.status.idle":"2023-11-16T11:09:51.147669Z","shell.execute_reply.started":"2023-11-16T11:09:51.139096Z","shell.execute_reply":"2023-11-16T11:09:51.146716Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def create_submission_files(test_preds, config, notebook='02'):\n    for col in test_preds.columns:\n        sub = sample_sub.copy()\n        sub[TARGET] = test_preds[col].round(4)\n        sub.to_csv(f'{notebook}_{config}_{col}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.152517Z","iopub.execute_input":"2023-11-16T11:09:51.153225Z","iopub.status.idle":"2023-11-16T11:09:51.160813Z","shell.execute_reply.started":"2023-11-16T11:09:51.153198Z","shell.execute_reply":"2023-11-16T11:09:51.160100Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"op = {} # OOF preds \ntp = {} # Test preds","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.170285Z","iopub.execute_input":"2023-11-16T11:09:51.170546Z","iopub.status.idle":"2023-11-16T11:09:51.174400Z","shell.execute_reply.started":"2023-11-16T11:09:51.170524Z","shell.execute_reply":"2023-11-16T11:09:51.173570Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Trial run:**","metadata":{}},{"cell_type":"code","source":"optuna.logging.set_verbosity(optuna.logging.INFO)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.179262Z","iopub.execute_input":"2023-11-16T11:09:51.179538Z","iopub.status.idle":"2023-11-16T11:09:51.184738Z","shell.execute_reply.started":"2023-11-16T11:09:51.179515Z","shell.execute_reply":"2023-11-16T11:09:51.183787Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"_ , _ = run_experiment(feature_set=features, n_trials=5)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:09:51.234993Z","iopub.execute_input":"2023-11-16T11:09:51.235815Z","iopub.status.idle":"2023-11-16T11:10:24.596836Z","shell.execute_reply.started":"2023-11-16T11:09:51.235782Z","shell.execute_reply":"2023-11-16T11:10:24.595902Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"[I 2023-11-16 11:09:51,238] A new study created in memory with name: no-name-0cff868c-a376-48d7-af7b-fff825b192e9\n","output_type":"stream"},{"name":"stdout","text":"----------Hyperparameter tuning----------\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-11-16 11:10:00,264] Trial 0 finished with value: 0.6261320590972899 and parameters: {'learning_rate': 0.01, 'max_depth': 12, 'min_child_weight': 8, 'gamma': 4.800000000000001, 'alpha': 2.6500000000000004, 'lambda': 0.25836603306052985}. Best is trial 0 with value: 0.6261320590972899.\n[I 2023-11-16 11:10:02,121] Trial 1 finished with value: 0.6737160682678223 and parameters: {'learning_rate': 0.09, 'max_depth': 3, 'min_child_weight': 3, 'gamma': 15.4, 'alpha': 0.25, 'lambda': 225.5637136810315}. Best is trial 0 with value: 0.6261320590972899.\n[I 2023-11-16 11:10:08,743] Trial 2 finished with value: 0.7018554210662842 and parameters: {'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 13, 'gamma': 18.0, 'alpha': 4.95, 'lambda': 4.7801281415139325}. Best is trial 0 with value: 0.6261320590972899.\n[I 2023-11-16 11:10:11,548] Trial 3 finished with value: 0.6601581573486328 and parameters: {'learning_rate': 0.04, 'max_depth': 11, 'min_child_weight': 7, 'gamma': 12.9, 'alpha': 0.1, 'lambda': 352.758317278758}. Best is trial 0 with value: 0.6261320590972899.\n[I 2023-11-16 11:10:15,015] Trial 4 finished with value: 0.6473712921142578 and parameters: {'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 12, 'gamma': 8.0, 'alpha': 4.55, 'lambda': 39.69974070824436}. Best is trial 0 with value: 0.6261320590972899.\n","output_type":"stream"},{"name":"stdout","text":"Best trial: 0 -> Best value: 0.62613\nBest hyperparameters:\nlearning_rate   - 0.01\nmax_depth       - 12\nmin_child_weight - 8\ngamma           - 4.800000000000001\nalpha           - 2.6500000000000004\nlambda          - 0.25836603306052985\n\n[Time taken: 23.86s]\n\n-----Cross-validation and prediction-----\nFold #0: 0.67571 (297 rounds)\nFold #1: 0.60840 (626 rounds)\nFold #2: 0.54929 (624 rounds)\nFold #3: 0.58701 (571 rounds)\nFold #4: 0.68517 (497 rounds)\n\nOOF score: 0.62613\n\n[Time taken: 9.50s]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"optuna.logging.set_verbosity(optuna.logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:10:24.598766Z","iopub.execute_input":"2023-11-16T11:10:24.599150Z","iopub.status.idle":"2023-11-16T11:10:24.604008Z","shell.execute_reply.started":"2023-11-16T11:10:24.599100Z","shell.execute_reply":"2023-11-16T11:10:24.603018Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# 7-folds","metadata":{}},{"cell_type":"code","source":"%%time\nnum_folds = 7\nconfig = f'trn_{num_folds}f'\n\nop[config], tp[config] = run_experiment(\n    feature_set=features,\n    num_folds=num_folds,\n    seed=SEED,\n    n_trials=200,\n    extended=False)\n\ncreate_submission_files(tp[config], config)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:10:24.605300Z","iopub.execute_input":"2023-11-16T11:10:24.605627Z","iopub.status.idle":"2023-11-16T11:28:12.286105Z","shell.execute_reply.started":"2023-11-16T11:10:24.605604Z","shell.execute_reply":"2023-11-16T11:28:12.285183Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 102 -> Best value: 0.51891\nBest hyperparameters:\nlearning_rate   - 0.09999999999999999\nmax_depth       - 9\nmin_child_weight - 14\ngamma           - 0.2\nalpha           - 0.55\nlambda          - 133.49333146667357\n\n[Time taken: 1062.01s]\n\n-----Cross-validation and prediction-----\nFold #0: 0.53085 (196 rounds)\nFold #1: 0.52577 (93 rounds)\nFold #2: 0.52332 (56 rounds)\nFold #3: 0.46749 (47 rounds)\nFold #4: 0.46208 (42 rounds)\nFold #5: 0.57301 (83 rounds)\nFold #6: 0.52911 (69 rounds)\n\nOOF score: 0.51891\n\n[Time taken: 5.51s]\n\nCPU times: user 21min 9s, sys: 19.6 s, total: 21min 28s\nWall time: 17min 47s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nnum_folds = 7\nconfig = f'ext_{num_folds}f'\n\nop[config], tp[config] = run_experiment(\n    feature_set=features,\n    num_folds=num_folds,\n    seed=SEED,\n    n_trials=200,\n    extended=True)\n\ncreate_submission_files(tp[config], config)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:28:12.288052Z","iopub.execute_input":"2023-11-16T11:28:12.288380Z","iopub.status.idle":"2023-11-16T11:46:43.706714Z","shell.execute_reply.started":"2023-11-16T11:28:12.288354Z","shell.execute_reply":"2023-11-16T11:46:43.705800Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 117 -> Best value: 0.51588\nBest hyperparameters:\nlearning_rate   - 0.060000000000000005\nmax_depth       - 12\nmin_child_weight - 8\ngamma           - 0.2\nalpha           - 0.55\nlambda          - 202.72509410770408\n\n[Time taken: 1102.56s]\n\n-----Cross-validation and prediction-----\nFold #0: 0.53333 (156 rounds)\nFold #1: 0.50894 (102 rounds)\nFold #2: 0.52237 (171 rounds)\nFold #3: 0.49212 (97 rounds)\nFold #4: 0.44460 (68 rounds)\nFold #5: 0.54600 (255 rounds)\nFold #6: 0.52363 (208 rounds)\n\nOOF score: 0.51588\n\n[Time taken: 8.71s]\n\nCPU times: user 21min 56s, sys: 19 s, total: 22min 15s\nWall time: 18min 31s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 10-folds","metadata":{}},{"cell_type":"code","source":"%%time\nnum_folds = 10\nconfig = f'trn_{num_folds}f'\n\nop[config], tp[config] = run_experiment(\n    feature_set=features,\n    num_folds=num_folds,\n    seed=SEED,\n    n_trials=200,\n    extended=False)\n\ncreate_submission_files(tp[config], config)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:46:43.708075Z","iopub.execute_input":"2023-11-16T11:46:43.708787Z","iopub.status.idle":"2023-11-16T12:18:38.427119Z","shell.execute_reply.started":"2023-11-16T11:46:43.708750Z","shell.execute_reply":"2023-11-16T12:18:38.426089Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 185 -> Best value: 0.51546\nBest hyperparameters:\nlearning_rate   - 0.08\nmax_depth       - 9\nmin_child_weight - 2\ngamma           - 0.2\nalpha           - 2.2\nlambda          - 147.4271301019588\n\n[Time taken: 1906.78s]\n\n-----Cross-validation and prediction-----\nFold #0: 0.54178 (60 rounds)\nFold #1: 0.51799 (130 rounds)\nFold #2: 0.52737 (53 rounds)\nFold #3: 0.52150 (87 rounds)\nFold #4: 0.48446 (53 rounds)\nFold #5: 0.44689 (54 rounds)\nFold #6: 0.43643 (48 rounds)\nFold #7: 0.55066 (81 rounds)\nFold #8: 0.51854 (72 rounds)\nFold #9: 0.54841 (113 rounds)\n\nOOF score: 0.51546\n\n[Time taken: 7.72s]\n\nCPU times: user 36min 53s, sys: 38.1 s, total: 37min 31s\nWall time: 31min 54s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nnum_folds = 10\nconfig = f'ext_{num_folds}f'\n\nop[config], tp[config] = run_experiment(\n    feature_set=features,\n    num_folds=num_folds,\n    seed=SEED,\n    n_trials=200,\n    extended=True)\n\ncreate_submission_files(tp[config], config)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T12:18:38.428344Z","iopub.execute_input":"2023-11-16T12:18:38.428646Z","iopub.status.idle":"2023-11-16T12:43:28.281168Z","shell.execute_reply.started":"2023-11-16T12:18:38.428621Z","shell.execute_reply":"2023-11-16T12:43:28.280280Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 55 -> Best value: 0.51743\nBest hyperparameters:\nlearning_rate   - 0.09999999999999999\nmax_depth       - 8\nmin_child_weight - 15\ngamma           - 0.0\nalpha           - 1.4000000000000001\nlambda          - 10.534123248212456\n\n[Time taken: 1481.70s]\n\n-----Cross-validation and prediction-----\nFold #0: 0.55269 (51 rounds)\nFold #1: 0.52987 (57 rounds)\nFold #2: 0.51818 (250 rounds)\nFold #3: 0.49700 (43 rounds)\nFold #4: 0.48842 (43 rounds)\nFold #5: 0.47504 (96 rounds)\nFold #6: 0.44574 (41 rounds)\nFold #7: 0.54882 (163 rounds)\nFold #8: 0.55131 (102 rounds)\nFold #9: 0.54670 (66 rounds)\n\nOOF score: 0.51743\n\n[Time taken: 7.95s]\n\nCPU times: user 29min 37s, sys: 28.3 s, total: 30min 6s\nWall time: 24min 49s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 20-folds","metadata":{}},{"cell_type":"code","source":"%%time\nnum_folds = 20\nconfig = f'trn_{num_folds}f'\n\nop[config], tp[config] = run_experiment(\n    feature_set=features,\n    num_folds=num_folds,\n    seed=SEED,\n    n_trials=200,\n    extended=False)\n\ncreate_submission_files(tp[config], config)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T12:43:28.282375Z","iopub.execute_input":"2023-11-16T12:43:28.282670Z","iopub.status.idle":"2023-11-16T13:29:27.493423Z","shell.execute_reply.started":"2023-11-16T12:43:28.282646Z","shell.execute_reply":"2023-11-16T13:29:27.492504Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 185 -> Best value: 0.51752\nBest hyperparameters:\nlearning_rate   - 0.09\nmax_depth       - 11\nmin_child_weight - 9\ngamma           - 0.2\nalpha           - 1.1500000000000001\nlambda          - 79.75257250800276\n\n[Time taken: 2741.63s]\n\n-----Cross-validation and prediction-----\nFold #0: 0.52203 (119 rounds)\nFold #1: 0.52665 (76 rounds)\nFold #2: 0.57429 (38 rounds)\nFold #3: 0.49775 (66 rounds)\nFold #4: 0.48106 (61 rounds)\nFold #5: 0.57461 (49 rounds)\nFold #6: 0.49460 (57 rounds)\nFold #7: 0.50088 (39 rounds)\nFold #8: 0.48474 (50 rounds)\nFold #9: 0.49653 (65 rounds)\nFold #10: 0.46657 (44 rounds)\nFold #11: 0.49247 (71 rounds)\nFold #12: 0.44685 (46 rounds)\nFold #13: 0.43469 (47 rounds)\nFold #14: 0.51547 (70 rounds)\nFold #15: 0.58086 (85 rounds)\nFold #16: 0.53296 (156 rounds)\nFold #17: 0.53891 (80 rounds)\nFold #18: 0.51983 (117 rounds)\nFold #19: 0.57706 (78 rounds)\n\nOOF score: 0.51752\n\n[Time taken: 17.17s]\n\nCPU times: user 55min 9s, sys: 56.1 s, total: 56min 5s\nWall time: 45min 59s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nnum_folds = 20\nconfig = f'ext_{num_folds}f'\n\nop[config], tp[config] = run_experiment(\n    feature_set=features,\n    num_folds=num_folds,\n    seed=SEED,\n    n_trials=200,\n    extended=True)\n\ncreate_submission_files(tp[config], config)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:29:27.494695Z","iopub.execute_input":"2023-11-16T13:29:27.495094Z","iopub.status.idle":"2023-11-16T14:17:30.792319Z","shell.execute_reply.started":"2023-11-16T13:29:27.495060Z","shell.execute_reply":"2023-11-16T14:17:30.791329Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 16 -> Best value: 0.51561\nBest hyperparameters:\nlearning_rate   - 0.09\nmax_depth       - 7\nmin_child_weight - 9\ngamma           - 0.2\nalpha           - 1.1\nlambda          - 24.723667786983253\n\n[Time taken: 2866.56s]\n\n-----Cross-validation and prediction-----\nFold #0: 0.52019 (188 rounds)\nFold #1: 0.56674 (106 rounds)\nFold #2: 0.53570 (100 rounds)\nFold #3: 0.50895 (165 rounds)\nFold #4: 0.48090 (65 rounds)\nFold #5: 0.59914 (62 rounds)\nFold #6: 0.49782 (55 rounds)\nFold #7: 0.49330 (72 rounds)\nFold #8: 0.50575 (43 rounds)\nFold #9: 0.47402 (175 rounds)\nFold #10: 0.45444 (67 rounds)\nFold #11: 0.47456 (223 rounds)\nFold #12: 0.45530 (41 rounds)\nFold #13: 0.43123 (47 rounds)\nFold #14: 0.50368 (104 rounds)\nFold #15: 0.60525 (117 rounds)\nFold #16: 0.51470 (100 rounds)\nFold #17: 0.54612 (146 rounds)\nFold #18: 0.55273 (99 rounds)\nFold #19: 0.58075 (278 rounds)\n\nOOF score: 0.51561\n\n[Time taken: 16.34s]\n\nCPU times: user 57min 40s, sys: 53.7 s, total: 58min 34s\nWall time: 48min 3s\n","output_type":"stream"}]},{"cell_type":"code","source":"!head 02_ext_20f_mean.csv","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:17:30.793615Z","iopub.execute_input":"2023-11-16T14:17:30.793930Z","iopub.status.idle":"2023-11-16T14:17:31.766825Z","shell.execute_reply.started":"2023-11-16T14:17:30.793902Z","shell.execute_reply":"2023-11-16T14:17:31.765707Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"id,Hardness\n10407,2.5861\n10408,2.5505\n10409,5.9508\n10410,4.2916\n10411,5.0037\n10412,4.773\n10413,3.547\n10414,5.6948\n10415,2.9139\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Time to submit!**","metadata":{}}]}
