{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import gc\nimport time\nimport warnings\n\ngc.enable()\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import clear_output\n\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 4)\n\nfrom sklearn.metrics import \nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport xgboost as xgb\nimport optuna\n\nSEED = 2024","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check GPU availability\nimport subprocess\n\ntry:\n    subprocess.check_output('nvidia-smi')\n    DEVICE = 'cuda'\nexcept Exception:\n    DEVICE = 'cpu'\n\nprint(f'Available device: {DEVICE}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = ''\n\ntrain = pd.read_csv(f'{DATA_DIR}/train.csv')\ntest = pd.read_csv(f'{DATA_DIR}/test.csv')\nsample_sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"# dropping irrelevant columns\ncols_to_drop = []\n\ntrain = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET = ''\nfeatures = [f for f in test.columns]\ncat_features = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[cat_features] = train[cat_features].astype('category')\ntest[cat_features] = test[cat_features].astype('category')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature sets\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"def objective(trial, feature_set, model, cv, stratify_col):\n    scores = []\n    \n    param_grid = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, step=0.01),\n        'max_depth': trial.suggest_int('max_depth', 3, 12),\n        'min_child_weight': trial.suggest_int('min_child_weight', 2, 64),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.05),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.05),\n        'gamma': trial.suggest_float('gamma', 0, 20, step=0.1), #complexity-control\n        'alpha': trial.suggest_float('alpha', 0, 5, step=0.1), #L1-reg\n        'lambda': trial.suggest_float('lambda', 5e-3, 5e3, log=True), #L2-reg\n#         'max_delta_step': trial.suggest_float('max_delta_step', 0, 10, step=0.5),\n        'max_cat_to_onehot': trial.suggest_categorical('max_cat_to_onehot', [2, 4])\n    }\n    \n    for fold, (train_ids, val_ids) in enumerate(cv.split(train, stratify_col)):\n        X_train, y_train = train[feature_set].iloc[train_ids], train[TARGET].iloc[train_ids]\n        X_val, y_val = train[feature_set].iloc[val_ids], train[TARGET].iloc[val_ids]\n        \n        model.set_params(**param_grid)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=0)\n    \n        val_preds = model.predict(X_val)\n        scores.append(comp_metric(y_val, val_preds))\n        \n    return np.mean(scores)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tune_params(feature_set, model, cv, stratify_col, seed, n_trials, direction):\n    study = optuna.create_study(\n        sampler=optuna.samplers.TPESampler(\n            consider_endpoints=True,\n            multivariate=True,\n            group=True,\n            seed=seed),\n        pruner=optuna.pruners.HyperbandPruner(),\n        direction=direction)\n    \n    study.optimize(\n        func=lambda trial: objective(\n            trial, feature_set, model, cv, stratify_col),\n        n_trials=n_trials,\n        gc_after_trial=True)\n    \n    return study","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling framework","metadata":{}},{"cell_type":"code","source":"def comp_metric(y_true, y_pred):\n    pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_cv(feature_set, model, cv, stratify_col, verbose=False):\n    X_test = test[feature_set]\n    \n    oof_preds, test_preds = {}, {}\n    scores = []\n\n    for fold, (train_ids, val_ids) in enumerate(cv.split(train, stratify_col)):\n        X_train, y_train = train[feature_set].iloc[train_ids], train[TARGET].iloc[train_ids]\n        X_val, y_val = train[feature_set].iloc[val_ids], train[TARGET].iloc[val_ids]\n\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=False)\n\n        val_preds = model.predict(X_val)\n        oof_preds.update(dict(zip(val_ids, val_preds)))\n        test_preds[f'fold{fold}'] = model.predict(X_test)\n\n        score = comp_metric(y_val, val_preds)\n        scores.append(score)\n        if verbose:\n            print(f'Fold #{fold:>2}: {score:.5f} ({model.best_iteration_:>4} rounds)')\n        _ = gc.collect()\n\n    test_preds = pd.DataFrame.from_dict(test_preds)\n    test_preds['mean'] = test_preds.mean(axis=1) # mean of fold-wise predictions\n    \n    oof_preds = pd.Series(oof_preds).sort_index()\n    print(f'\\nAvg score: {np.mean(scores):.5f} +/- {np.std(scores):.5f}')\n    print(f'OOF score: {comp_metric(train[TARGET], oof_preds):.5f}\\n')\n    \n    return oof_preds, test_preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_experiment(feature_set, stratify_col=None, seed=SEED, n_trials=200):\n    \n    base_params = {\n        'booster': 'gbtree',\n        'tree_method': 'hist',\n        'objective': '',\n        'eval_metric': '',\n        'learning_rate': 0.01,\n        'n_estimators': 10000,\n        'early_stopping_rounds': 100,\n        'device': DEVICE,\n        'enable_categorical': True,\n        'verbosity': 0,\n        'n_jobs': -1,\n        'seed': seed\n    }\n    model = xgb.XGBRegressor(**base_params)\n    \n    start = time.time()\n    study = tune_params(features, model, cv, seed, n_trials, direction='minimize') \n    end = time.time()\n    \n    clear_output(wait=True)\n    print(f'----------Hyperparameter tuning----------')\n    print(f'Best trial: {study.best_trial.number} -> Best value: {study.best_value:.5f}')\n    print(f'Best hyperparameters:')\n    for k, v in study.best_params.items():\n        print(f'{k:20} - {v}')\n    print(f'\\n[Time taken: {end - start:.2f}s]\\n')\n    \n    print(f'-----Cross-validation and prediction-----')\n    start = time.time()\n    \n    model.set_params(**study.best_params)\n    oof_preds, test_preds = custom_cv(features, model, cv, stratify_col)\n    \n    end = time.time()\n    print(f'\\n[Time taken: {end - start:.2f}s]\\n')\n    \n    return oof_preds, test_preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission_files(preds, config, notebook=):\n    for col in preds.columns:\n        sub = sample_sub.copy()\n        sub[TARGET] = preds[col]  # include postprocessing\n        sub.to_csv(f'nb{notebook}_{config}_{col}.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op = {}  # OOF preds\ntp = {}  # Test preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiments","metadata":{}},{"cell_type":"code","source":"optuna.logging.set_verbosity(optuna.logging.INFO)\n_ , _ = run_experiment(features=features, n_trials=3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfeature_set =\nfolds = \nstratify_col = \nseed = \nconfig = f'feat{feature_set}_fold{folds}__seed{seed}'\n\nop[config], tp[config] = run_experiment(\n    feature_set=,  \n    stratify_col=, \n    seed=seed)\n\ncreate_submission_files(tp[config], config)","metadata":{},"execution_count":null,"outputs":[]}]}